{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/localdata/geng/lib/lmtc-eurlex57k\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import tempfile\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import Sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "from json_loader import JSONLoader\n",
    "from vectorizer import W2VVectorizer, ELMoVectorizer, BERTVectorizer\n",
    "from data import DATA_SET_DIR, MODELS_DIR\n",
    "from configuration import Configuration\n",
    "from metrics import mean_recall_k, mean_precision_k, mean_ndcg_score, mean_rprecision_k\n",
    "from neural_networks.lmtc_networks.document_classification import DocumentClassification\n",
    "from neural_networks.lmtc_networks.label_driven_classification import LabelDrivenClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Configuration.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load labels' data\n",
      "-------------------\n",
      "100%|██████████| 45000/45000 [01:58<00:00, 380.70it/s] \n",
      "100%|██████████| 12000/12000 [00:23<00:00, 501.91it/s] \n",
      "Labels shape:    4271\n",
      "Frequent labels: 739\n",
      "Few labels:      3369\n",
      "Zero labels:     163\n"
     ]
    }
   ],
   "source": [
    "lmtc=lmtc.LMTC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = LabelDrivenClassification(lmtc.label_terms_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11820,     0,     0, ...,     0,     0,     0],\n",
       "       [  485,   310,     0, ...,     0,     0,     0],\n",
       "       [  485,   324,  3908, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [ 1271,  2998,     0, ...,     0,     0,     0],\n",
       "       [  723,     6,  1070, ...,     0,     0,     0],\n",
       "       [  172,   566,   176, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmtc.label_terms_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"/mnt/localdata/geng/model/downstream/multiLabelClassification/legalBert/prediction.pickle\", \"rb\") as f:\n",
    "    pred_labels,true_labels=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07959438"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    1/(1+exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50015305, 0.50024703, 0.50016784, ..., 0.50010097, 0.50020254,\n",
       "        0.50016558],\n",
       "       [0.50015305, 0.50024703, 0.50016789, ..., 0.50010098, 0.50020257,\n",
       "        0.50016558],\n",
       "       [0.50015306, 0.50024703, 0.50016786, ..., 0.50010098, 0.50020257,\n",
       "        0.50016558],\n",
       "       ...,\n",
       "       [0.50015304, 0.50024702, 0.50016786, ..., 0.50010098, 0.50020256,\n",
       "        0.50016558],\n",
       "       [0.50015305, 0.50024702, 0.50016787, ..., 0.50010097, 0.50020258,\n",
       "        0.50016557],\n",
       "       [0.50015304, 0.50024703, 0.50016786, ..., 0.50010097, 0.50020256,\n",
       "        0.50016557]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = lambda x: 1/(1+exp(-x))\n",
    "vfunc = np.vectorize(sigmoid)\n",
    "vfunc(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels=np.array(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(map(sigmoid, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-2f755f117ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6422567"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.sum(pred_labels,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=np.median(pred_labels)\n",
    "\n",
    "y_pred=(pred_labels>threshold).astype(int)\n",
    "\n",
    "np.sum(y_pred)/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels=np.array(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(pred_labels>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-463a2ef1e148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/localdata/geng/anaconda3/envs/lmtc_/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/localdata/geng/anaconda3/envs/lmtc_/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1927\u001b[0m     \"\"\"\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/localdata/geng/anaconda3/envs/lmtc_/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 91\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels=np.array(pred_labels)\n",
    "true_labels=np.array(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.42it/s]\n"
     ]
    }
   ],
   "source": [
    "test_documents = lmtc.load_dataset('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = len(test_documents) % Configuration['model']['batch_size'] if Configuration['model']['architecture'] == 'BERT' else 0\n",
    "test_samples, test_tags = lmtc.process_dataset(test_documents if not limit else test_documents[:-limit])\n",
    "test_samples, test_targets = lmtc.encode_dataset(test_samples, test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_samples, test_targets =test_samples[:100], test_targets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading projection weights from /mnt/localdata/geng/lib/lmtc-eurlex57k/data/vectors/law2vec.200d.txt\n",
      "loaded (169439, 200) matrix from /mnt/localdata/geng/lib/lmtc-eurlex57k/data/vectors/law2vec.200d.txt\n"
     ]
    }
   ],
   "source": [
    "network.compile(n_hidden_layers=Configuration['model']['n_hidden_layers'],\n",
    "                hidden_units_size=Configuration['model']['hidden_units_size'],\n",
    "                dropout_rate=Configuration['model']['dropout_rate'],\n",
    "                word_dropout_rate=Configuration['model']['word_dropout_rate'],\n",
    "                lr=Configuration['model']['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=lmtc.predict(network,test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 4193)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4271)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/localdata/geng/lib/lmtc-eurlex57k\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall\n",
      "----------------------------------------------------\n",
      "/mnt/localdata/geng/anaconda3/envs/lmtc_/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "micro    - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "/mnt/localdata/geng/anaconda3/envs/lmtc_/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/localdata/geng/anaconda3/envs/lmtc_/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/localdata/geng/anaconda3/envs/lmtc_/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1465: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "macro    - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "weighted - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "R@1 : 0.024   P@1 : 0.081   RP@1 : 0.081   NDCG@1 : 0.081\n",
      "R@2 : 0.040   P@2 : 0.082   RP@2 : 0.083   NDCG@2 : 0.082\n",
      "R@3 : 0.051   P@3 : 0.076   RP@3 : 0.078   NDCG@3 : 0.080\n",
      "R@4 : 0.063   P@4 : 0.073   RP@4 : 0.080   NDCG@4 : 0.081\n",
      "R@5 : 0.074   P@5 : 0.071   RP@5 : 0.082   NDCG@5 : 0.083\n",
      "R@6 : 0.086   P@6 : 0.070   RP@6 : 0.088   NDCG@6 : 0.087\n",
      "R@7 : 0.100   P@7 : 0.069   RP@7 : 0.101   NDCG@7 : 0.094\n",
      "R@8 : 0.112   P@8 : 0.067   RP@8 : 0.112   NDCG@8 : 0.099\n",
      "R@9 : 0.121   P@9 : 0.065   RP@9 : 0.121   NDCG@9 : 0.104\n",
      "R@10 : 0.130   P@10 : 0.063   RP@10 : 0.130   NDCG@10 : 0.109\n",
      "----------------------------------------------------\n",
      "Frequent Labels (>=50 Occurrences in train set)\n",
      "----------------------------------------------------\n",
      "micro    - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "macro    - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "weighted - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "R@1 : 0.075   P@1 : 0.122   RP@1 : 0.122   NDCG@1 : 0.122\n",
      "R@2 : 0.117   P@2 : 0.108   RP@2 : 0.130   NDCG@2 : 0.128\n",
      "R@3 : 0.161   P@3 : 0.103   RP@3 : 0.162   NDCG@3 : 0.147\n",
      "R@4 : 0.199   P@4 : 0.095   RP@4 : 0.200   NDCG@4 : 0.166\n",
      "R@5 : 0.238   P@5 : 0.091   RP@5 : 0.238   NDCG@5 : 0.183\n",
      "R@6 : 0.263   P@6 : 0.085   RP@6 : 0.263   NDCG@6 : 0.195\n",
      "R@7 : 0.277   P@7 : 0.078   RP@7 : 0.277   NDCG@7 : 0.201\n",
      "R@8 : 0.296   P@8 : 0.073   RP@8 : 0.296   NDCG@8 : 0.208\n",
      "R@9 : 0.315   P@9 : 0.068   RP@9 : 0.315   NDCG@9 : 0.214\n",
      "R@10 : 0.336   P@10 : 0.065   RP@10 : 0.336   NDCG@10 : 0.221\n",
      "----------------------------------------------------\n",
      "Few-shot (<=50 Occurrences in train set)\n",
      "----------------------------------------------------\n",
      "micro    - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "macro    - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "weighted - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "R@1 : 0.030   P@1 : 0.082   RP@1 : 0.082   NDCG@1 : 0.082\n",
      "R@2 : 0.050   P@2 : 0.073   RP@2 : 0.075   NDCG@2 : 0.077\n",
      "R@3 : 0.069   P@3 : 0.070   RP@3 : 0.079   NDCG@3 : 0.079\n",
      "R@4 : 0.086   P@4 : 0.069   RP@4 : 0.089   NDCG@4 : 0.085\n",
      "R@5 : 0.099   P@5 : 0.065   RP@5 : 0.100   NDCG@5 : 0.092\n",
      "R@6 : 0.113   P@6 : 0.062   RP@6 : 0.114   NDCG@6 : 0.099\n",
      "R@7 : 0.124   P@7 : 0.059   RP@7 : 0.124   NDCG@7 : 0.104\n",
      "R@8 : 0.134   P@8 : 0.057   RP@8 : 0.134   NDCG@8 : 0.109\n",
      "R@9 : 0.142   P@9 : 0.054   RP@9 : 0.142   NDCG@9 : 0.113\n",
      "R@10 : 0.152   P@10 : 0.052   RP@10 : 0.152   NDCG@10 : 0.117\n",
      "----------------------------------------------------\n",
      "Zero-shot (No Occurrences in train set)\n",
      "----------------------------------------------------\n",
      "micro    - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "macro    - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "weighted - Precision: 0.0000   Recall: 0.0000   F1: 0.0000\n",
      "R@1 : 0.129   P@1 : 0.132   RP@1 : 0.132   NDCG@1 : 0.132\n",
      "R@2 : 0.244   P@2 : 0.140   RP@2 : 0.244   NDCG@2 : 0.207\n",
      "R@3 : 0.372   P@3 : 0.137   RP@3 : 0.372   NDCG@3 : 0.271\n",
      "R@4 : 0.458   P@4 : 0.125   RP@4 : 0.458   NDCG@4 : 0.308\n",
      "R@5 : 0.528   P@5 : 0.115   RP@5 : 0.528   NDCG@5 : 0.336\n",
      "R@6 : 0.575   P@6 : 0.109   RP@6 : 0.575   NDCG@6 : 0.355\n",
      "R@7 : 0.625   P@7 : 0.101   RP@7 : 0.625   NDCG@7 : 0.372\n",
      "R@8 : 0.658   P@8 : 0.092   RP@8 : 0.658   NDCG@8 : 0.383\n",
      "R@9 : 0.671   P@9 : 0.084   RP@9 : 0.671   NDCG@9 : 0.386\n",
      "R@10 : 0.671   P@10 : 0.075   RP@10 : 0.671   NDCG@10 : 0.386\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lmtc.calculate_performance(true_labels,pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lmtc' has no attribute 'load_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-987ea59e9b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'lmtc' has no attribute 'load_dataset'"
     ]
    }
   ],
   "source": [
    "documents = lmtc.load_dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load labels' data\n",
      "-------------------\n",
      "100%|██████████| 45000/45000 [00:35<00:00, 1256.18it/s]\n",
      "100%|██████████| 12000/12000 [00:09<00:00, 1242.48it/s]\n",
      "Labels shape:    4271\n",
      "Frequent labels: 739\n",
      "Few labels:      3369\n",
      "Zero labels:     163\n"
     ]
    }
   ],
   "source": [
    "lmtc.load_label_descriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [05:21<00:00, 18.69it/s]\n"
     ]
    }
   ],
   "source": [
    "test=lmtc.load_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SET_DIR=\"/mnt/localdata/geng/lib/lmtc-eurlex57k/data/datasets/\"\n",
    "\n",
    "MODELS_DIR=\"/mnt/localdata/geng/lib/lmtc-eurlex57k/data/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
